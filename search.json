[
  {
    "objectID": "points.html",
    "href": "points.html",
    "title": "points",
    "section": "",
    "text": "source\n\nin_hull\n\n in_hull (point:&lt;built-infunctionarray&gt;,\n          hull:scipy.spatial._qhull.ConvexHull, tol=1e-09)\n\nchecks whether point is inside hull\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npoint\narray\n\n1d array\n\n\nhull\nConvexHull\n\nsee scipy.spatial\n\n\ntol\nfloat\n1e-09\n\n\n\n\n\nsource\n\n\nPoints\n\n Points (n:int, d=2, seed:Optional[int]=None,\n         law:Literal['binomial','poisson']='binomial',\n         shape:Optional[scipy.spatial._qhull.ConvexHull]=None)\n\ndefine binomial or poisson point process in a convex polytope\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n\n(expected) number of points\n\n\nd\nint\n2\ndimensionality\n\n\nseed\ntyping.Optional[int]\nNone\n\n\n\nlaw\ntyping.Literal[‘binomial’, ‘poisson’]\nbinomial\ndistribution of the points\n\n\nshape\ntyping.Optional[scipy.spatial._qhull.ConvexHull]\nNone\nsample from shape, default to unit box\n\n\n\n\nimport matplotlib.pyplot as plt\n\n\nrng = np.random.default_rng()\nvertices = rng.uniform(0,10,size=(5,2))\nhull = ConvexHull(vertices)\nfor s in hull.simplices:\n    plt.plot(vertices[s,0], vertices[s,1])\n\n\n\n\n\n\n\n\n\nprocess = Points(1600,shape=hull)\nbin = process.points\np = np.array([0.5,0.5])\nprint(in_hull(p, hull))\nplt.scatter(*bin.T)\nplt.plot(*p, 'x')\nfor s in hull.simplices:\n    plt.plot(vertices[s,0], vertices[s,1])\n\nFalse\n\n\n\n\n\n\n\n\n\n\nPoints(5,d=3,shape=ConvexHull(np.random.default_rng().uniform(size=(4,3)))).points\n\narray([[0.77855289, 0.4850915 , 0.42972623],\n       [0.65133126, 0.45593755, 0.53063587],\n       [0.6736211 , 0.67348507, 0.18656676],\n       [0.59821495, 0.49935331, 0.47867237],\n       [0.63326363, 0.58585142, 0.37836227]])\n\n\n\nsource\n\n\nPoints.lnnl\n\n Points.lnnl (k:int=1)\n\ncomputes largest k-nearest neighbour link\n\nprocess.lnnl(), process.lnnl(2), process.lnnl(3)\n\n(0.1465206003726509, 0.23711929766470216, 0.24755948776583622)\n\n\n\nsource\n\n\nPoints.connectivity_threshold\n\n Points.connectivity_threshold (output_lnnl=False)\n\n\nprocess.connectivity_threshold()\n\n0.1782874408917787",
    "crumbs": [
      "points"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "geography",
    "section": "",
    "text": "pip install geography",
    "crumbs": [
      "geography"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "geography",
    "section": "",
    "text": "pip install geography",
    "crumbs": [
      "geography"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "geography",
    "section": "How to use",
    "text": "How to use\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import ConvexHull\n\nfrom geography.core import RGG\n\n\ncreate a random geometric graph\nwe can specify the law (support binomial and Poisson), a convex polytope in which vertices live, the average number of points and the connection radius.\n\nrgg = RGG(n=2000, r=0.05, d=2, shape=ConvexHull(np.random.default_rng().uniform(0,1,(5,2))*3), law=\"poisson\")\n\nsupported statitics\n\nadj: adjacency list\n\ndegree_distribution\n\nn_comp: number of component\n\nn_tri: number of triangles\n\ncyclic: bool of whether the graph is cyclic\n\nfor instance\n\nplt.bar(*rgg.degree_distribution().T)\n\n\n\n\n\n\n\n\n\n\nInspect the points\nUnder the hood, RGG has the V (standing for vertices) attribute which is implemented as a Points object. We can inspect the coordinates of V as follows\n\nplt.scatter(*rgg.V.points.T)\n\n\n\n\n\n\n\n\nEvery Points object come with a few methods\n\ndistance_matrix(): pairwise distance of points\nlnnl(k): largest k-nearest neighbour link defined by \\[\nL_k = \\inf\\{r: \\deg(x)\\ge k,  \\forall x\\in G(V,r) \\}\n\\]\nconnectivity_threshold(): \\[\nM = \\inf\\{r: G(V,r) \\text{ is connected}\\}.\n\\]\n\n\nrgg.V.lnnl(k=1)\n\n0.04809040392058131\n\n\n\nrgg.V.connectivity_threshold(output_lnnl=False)\n\n0.057453595670079224",
    "crumbs": [
      "geography"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nRGG\n\n RGG (n:int, r:float, d:int=2, law='binomial', shape=None)\n\nrandom geometric graph\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n\naverage number of points\n\n\nr\nfloat\n\nconnection radius\n\n\nd\nint\n2\ndimension\n\n\nlaw\nstr\nbinomial\neither poisson or binomial\n\n\nshape\nNoneType\nNone\nconvex polytope\n\n\n\n\nfrom scipy.spatial import ConvexHull\nimport seaborn.objects as so\n\n\nrgg = RGG(100,0.05, law=\"poisson\", shape=ConvexHull(np.random.default_rng().uniform(0,1,(6,2))))\nrgg.V.distance_matrix.shape # poisson number\n\n(105, 105)\n\n\n\np = so.Plot(x=rgg.V.points[:,0], y=rgg.V.points[:,1])\np.add(so.Dots())\n\n\n\n\n\n\n\n\n\nrgg.adj\n\n{0: [23, 30, 43, 72],\n 1: [9],\n 2: [34, 42, 83],\n 3: [8],\n 4: [50, 71, 85, 88, 90],\n 5: [20, 44, 49, 50, 73, 101],\n 6: [87, 90],\n 7: [33, 76, 86, 89],\n 8: [3],\n 9: [1, 77, 94],\n 10: [36, 55, 66, 92, 99],\n 11: [],\n 12: [13, 27, 82],\n 13: [12, 67],\n 14: [16, 45, 57, 92],\n 15: [25, 52, 98],\n 16: [14, 45, 57],\n 17: [60],\n 18: [24, 47, 65, 68],\n 19: [58, 91],\n 20: [5, 44, 49, 61, 69, 73],\n 21: [22, 26, 44, 69, 93, 103],\n 22: [21, 26, 46, 93, 103],\n 23: [0, 30, 43, 72],\n 24: [18, 47, 65, 68],\n 25: [15, 52, 86, 98],\n 26: [21, 22, 31, 84],\n 27: [12, 82],\n 28: [],\n 29: [62],\n 30: [0, 23, 43, 48, 95],\n 31: [26, 84],\n 32: [61, 73, 100],\n 33: [7, 76, 86, 98],\n 34: [2, 42, 59, 83],\n 35: [],\n 36: [10, 55, 66, 96, 99],\n 37: [43],\n 38: [80, 89],\n 39: [],\n 40: [76, 89],\n 41: [78],\n 42: [2, 34, 95],\n 43: [0, 23, 30, 37, 95],\n 44: [5, 20, 21, 61, 69, 73, 93, 101],\n 45: [14, 16, 57, 92],\n 46: [22, 102, 103],\n 47: [18, 24],\n 48: [30, 53, 95],\n 49: [5, 20, 50, 61, 73],\n 50: [4, 5, 49, 90, 101],\n 51: [],\n 52: [15, 25, 96, 98, 104],\n 53: [48, 95],\n 54: [60, 75, 79],\n 55: [10, 36, 66, 92],\n 56: [63, 85, 88],\n 57: [14, 16, 45, 92],\n 58: [19, 91],\n 59: [34, 83],\n 60: [17, 54, 79],\n 61: [20, 32, 44, 49, 65, 69, 73, 100],\n 62: [29],\n 63: [56, 71, 85, 88],\n 64: [],\n 65: [18, 24, 61, 73],\n 66: [10, 36, 55],\n 67: [13, 82],\n 68: [18, 24],\n 69: [20, 21, 44, 61, 73],\n 70: [75, 102],\n 71: [4, 63, 85, 88, 101],\n 72: [0, 23],\n 73: [5, 20, 32, 44, 49, 61, 65, 69],\n 74: [99],\n 75: [54, 70, 79, 102],\n 76: [7, 33, 40, 86, 89],\n 77: [9],\n 78: [41],\n 79: [54, 60, 75],\n 80: [38, 89],\n 81: [97],\n 82: [12, 27, 67],\n 83: [2, 34, 59],\n 84: [26, 31],\n 85: [4, 56, 63, 71, 88],\n 86: [7, 25, 33, 76, 98],\n 87: [6],\n 88: [4, 56, 63, 71, 85, 90],\n 89: [7, 38, 40, 76, 80],\n 90: [4, 6, 50, 88],\n 91: [19, 58],\n 92: [10, 14, 45, 55, 57],\n 93: [21, 22, 44, 101, 103],\n 94: [9],\n 95: [30, 42, 43, 48, 53],\n 96: [36, 52, 99, 104],\n 97: [81],\n 98: [15, 25, 33, 52, 86, 104],\n 99: [10, 36, 74, 96],\n 100: [32, 61],\n 101: [5, 44, 50, 71, 93],\n 102: [46, 70, 75],\n 103: [21, 22, 46, 93],\n 104: [52, 96, 98]}\n\n\n\nsource\n\n\nRGG.n_comp\n\n RGG.n_comp ()\n\n\nrgg.n_comp()\n\n16\n\n\n\nsource\n\n\nRGG.degree_distribution\n\n RGG.degree_distribution ()\n\n\nd_np = rgg.degree_distribution()\nd_np\n\narray([[ 4, 20],\n       [ 1, 15],\n       [ 3, 18],\n       [ 5, 19],\n       [ 6,  5],\n       [ 2, 19],\n       [ 0,  6],\n       [ 8,  3]])\n\n\n\n(\n    so.Plot(x=d_np[:,0], y=d_np[:,1])\n    .add(so.Line())\n)\n\n\n\n\n\n\n\n\n\nsource\n\n\nRGG.cyclic\n\n RGG.cyclic ()\n\n\nrgg.cyclic()\n\nTrue\n\n\n\nsource\n\n\nRGG.n_tri\n\n RGG.n_tri ()\n\n\nrgg.n_tri()\n\n94",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "sparse_matrices_test.html",
    "href": "sparse_matrices_test.html",
    "title": "sparse distance matrix test",
    "section": "",
    "text": "import numpy as np\nfrom scipy.spatial import KDTree\nfrom sys import getsizeof\nimport timeit\n\nrng = np.random.default_rng()\n\n\ndef full_matrix_experiment(n,d=2):\n    # generates the (full) distance matrix for an RGG with n points in [0,1]^d,\n    # and returns the amount of memory it uses.\n    V = rng.uniform(size=(n,d))\n    dm =  np.linalg.norm(V[:,None,:] - V[None,:,:],axis=-1)\n    return dm.size\n\ndef sparse_matrix_experiment(n,r_max,d=2):\n    V = rng.uniform(size=(n,d))\n    tree = KDTree(V)\n    sdm = tree.sparse_distance_matrix(tree, r_max)\n    return sdm.count_nonzero()\n\nLet’s check both the size of the resulting matrices, and how long it takes to generate them:\n\nn = 5000\nd = 3\nr = 4*(np.log(n)/n)**(1/d) # Quite a bit above the coverage threshold for the square, so the test isn't too biased in favour of the sparse matrix\nreps = 5\n\nprint(f'Number of elements in the sparse distance matrix with radius {r:.3f}: {sparse_matrix_experiment(n,r,d)}')\nprint(f'Number of elements in the usual distance matrix:                    {full_matrix_experiment(n,d)}\\n')\n\nprint(f'Time taken to generate {reps} sparse distance matrices (in seconds):')\nprint(sum(timeit.repeat(f'sparse_matrix_experiment({n},{r},{d})',repeat=reps,globals=globals(),number=1)))\nprint(f'Time taken to generate {reps} usual distance matrices (in seconds):')\nprint(sum(timeit.repeat(f'full_matrix_experiment({n},{d})',repeat=reps,globals=globals(),number=1)))\n\nNumber of elements in the sparse distance matrix with radius 0.478: 6178320\nNumber of elements in the usual distance matrix:                    25000000\n\nTime taken to generate 5 sparse distance matrices (in seconds):\n\n\nThe results are interesting: I think they provide a good case for using sparse distance matrices. Maybe I’ll do a few more experiments by trying to calculate the number of components using a sparse distance matrix: this may or may not be quicker.\nGenerating a usual distance matrix is a bit quicker when \\(r = 4 ( \\frac{\\log n}{n} )^{1/d}\\), but this is generally much larger than the coverage threshold. If \\(r = 2 (\\frac{\\log n}{n})^{1/d}\\), then generating a sparse distance matrix seems faster (it’s also possible to just convert a 2d numpy array straight into a scipy.sparse.dok_array type sparse array, so maybe we can do without the KDTree step. But I think for very large \\(n\\) the KDTree will be faster than usual linear algebra).\nA sparse distance matrix contains many fewer elements than the usual distance matrix. For every non-zero element it does also store the indices, so maybe you should triple the number of elements to get a comparable storage space, but even so it’s much smaller than the full distance matrix.\n\nn = 10000\nr = 2*(np.log(n)/n)**(1/2)\nsparse_matrix_experiment(n,r,d=2)\n\n1098822\n\n\nIn particular it’s possible to compute sparse distance matrices for more points; my computer runs out of memory when trying to compute the full distance matrix for more than around 6,000 points.",
    "crumbs": [
      "sparse distance matrix test"
    ]
  },
  {
    "objectID": "hawkes.html",
    "href": "hawkes.html",
    "title": "hawkes",
    "section": "",
    "text": "source\n\n\n\n find_next (f, points, t)\n\n\nsource\n\n\n\n\n update (f, t)\n\n\nsource\n\n\n\n\n h (x:&lt;built-infunctionarray&gt;, al=1.2)\n\nkernel function\n\nprint(find_next(h, rng.random((5,2)),0.5))\n\ntimes = rng.random((3,))*5\nf = h\nfor t in times:\n    f = update(f,t)\n\nx = np.linspace(0,5,100)\nplt.plot(x, f(x))\n\n2",
    "crumbs": [
      "hawkes"
    ]
  },
  {
    "objectID": "hawkes.html#helper-functions",
    "href": "hawkes.html#helper-functions",
    "title": "hawkes",
    "section": "",
    "text": "source\n\n\n\n find_next (f, points, t)\n\n\nsource\n\n\n\n\n update (f, t)\n\n\nsource\n\n\n\n\n h (x:&lt;built-infunctionarray&gt;, al=1.2)\n\nkernel function\n\nprint(find_next(h, rng.random((5,2)),0.5))\n\ntimes = rng.random((3,))*5\nf = h\nfor t in times:\n    f = update(f,t)\n\nx = np.linspace(0,5,100)\nplt.plot(x, f(x))\n\n2",
    "crumbs": [
      "hawkes"
    ]
  }
]